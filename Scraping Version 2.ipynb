{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Scraping\n",
    "\n",
    "## Part 1: BeautifulSoup\n",
    "\n",
    "BeautifulSoup Documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# If this isn't working, uncomment the following line to install (this is not the recommended way)\n",
    "# !pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Import the requests library, which underlies most of this tutorial\n",
    "# You don't actually need to know much more than requests.get(url) though # https://2.python-requests.org/en/v2.5.3/user/advanced/\n",
    "import requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to get the HTML of the page we are trying to scrape, in this case Worker Adjustment and Retraining Notification data from the NYC department of labor.\n",
    "https://labor.ny.gov/app/warn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify a target URL, and fetch the HTML \n",
    "warn_url = \"https://labor.ny.gov/app/warn/\"\n",
    "response = requests.get(warn_url)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a 200 (success) status code returned from the request. If you don't see this, you might not be connected to the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we only want 2020 data\n",
    "warn_2020_url = \"https://labor.ny.gov/app/warn/default.asp?warnYr=2020\"\n",
    "response = requests.get(warn_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a soup object to help parse the html\n",
    "\n",
    "[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python library that helps parse HTML files.\n",
    "\n",
    "Pass the HTML we requested from the WARN site to BeautifulSoup to create a 'soup' object for the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the WARN page\n",
    "\n",
    "[](img/warn.png)\n",
    "\n",
    "![WARN](img/warn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table looks like the thing we want to parse. We need a list of each link to a WARN record. Let's extract this list.\n",
    "\n",
    "\n",
    "### Quick HTML Syntax Review\n",
    "![HTML tag syntax](img/html-tag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the table with .find()\n",
    "\n",
    "[find()](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find) is the simplest of BeautifulSoup's HTML parsing methods. It will return the first HTML element that matches your query, in this case a Tag Name. Because there is only one table on the WARN page, this will work fine for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table\n",
    "table = soup.find('table')\n",
    "print('1', type(table))\n",
    "\n",
    "# This is does same thing, but the syntax is a little more simple\n",
    "table = soup.table\n",
    "print('2', type(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's one way to do it\n",
    "for item in table:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all()\n",
    "\n",
    "find_all() is identical to find(), except it will return a list of ALL occurances of your query.\n",
    "\n",
    "We call find_all() directly on the table we've already extracted, rather than the soup object. This way, we only find matches that are in the table, not other links on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all() called on the table. find_all() returns a list\n",
    "link_tags = table.find_all('a')\n",
    "print('number of links:', len(link_tags))\n",
    "\n",
    "# Take a look\n",
    "for link in link_tags:\n",
    "    print(link.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Attributes\n",
    "\n",
    "We want to look at each WARN record, so we need to get the url for each page. We can do this by accessing the href attribute from each 'a' (hyperlink) tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of links\n",
    "links = []\n",
    "\n",
    "# Iterate over each <a>\n",
    "for link in table.find_all('a'):\n",
    "    # Use the bracket notation to get an attribute from a tag\n",
    "    # print(link['href'])\n",
    "    \n",
    "    # add the current link text to the list\n",
    "    links.append(warn_url + link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gzip\n",
    "import unicodedata\n",
    "\n",
    "# Create a list to store the data we scrape.\n",
    "# Each item in the list will correspond to a single WARN listing\n",
    "# Each column will be a piece of single labeled piece information from the listing\n",
    "data = []\n",
    "\n",
    "def scrape_single_page(url):\n",
    "    \n",
    "    # Print the current URL that we're scraping\n",
    "    print('scraping', url, end='\\r')\n",
    "    \n",
    "    # Create a dictionary to store the data for a single WARN listing\n",
    "    page_data = {}\n",
    "    \n",
    "    # Fetch the page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # This is pretty atypical. Some of these pages are not being unzipped correctly\n",
    "    # If the request didn't automatically unzip the html, we have to do it ourselves\n",
    "    # We can check the encoding that the requests library thinks the page has returned\n",
    "    if response.apparent_encoding is None:\n",
    "        html = gzip.decompress(response.content).decode('utf-8')\n",
    "    else:\n",
    "        html = response.text\n",
    "        \n",
    "    # Remove non-breaking space characters in the HTML\n",
    "    html = html.replace('&nbsp;', ' ')\n",
    "    \n",
    "    # Make the soup for the single page\n",
    "    page_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Sanity check\n",
    "    # print(page_soup.prettify())\n",
    "    \n",
    "    # Get the first table (there should only be one)\n",
    "    table = page_soup.table\n",
    "    \n",
    "    # Get each paragraph tag\n",
    "    paragraphs = table.find_all('p')\n",
    "    \n",
    "    # Use .text to get the inner text for each p\n",
    "    for paragraph in paragraphs:\n",
    "        # print(paragraph.text)\n",
    "        text = paragraph.text\n",
    "        \n",
    "        # We are going to split on only the first colon in each row (':') by using text.split(delim, 1)\n",
    "        split_text = text.split(':', 1)\n",
    "        \n",
    "        if len(split_text) == 2:\n",
    "            # Add this paragraph to the page data\n",
    "            page_data[split_text[0]] = split_text[1]\n",
    "        \n",
    "        \n",
    "    # After looping through each paragraph, add this listing to the DataFrame\n",
    "    data.append(page_data)\n",
    "\n",
    "for link in links:\n",
    "    scrape_single_page(link)\n",
    "    \n",
    "    # This is the most important line in the entire notebook\n",
    "    # This line ensures that you won't crash servers and make peoople come knocking on your door\n",
    "    # Don't be an idiot!\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame to store the data we scrape.\n",
    "# Each row in the dataframe will correspond to a single WARN listing\n",
    "# Each column will be a piece of single labeled piece information from the listing\n",
    "data = []\n",
    "\n",
    "def scrape_single_page(url):\n",
    "    \n",
    "    # Create a dictionary to store the data for a single WARN listing\n",
    "    page_data = {}\n",
    "    \n",
    "    # Fetch the page\n",
    "    response = requests.get(url)\n",
    "    page_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Sanity check\n",
    "    # print(page_soup.prettify())\n",
    "    \n",
    "    # Get the first/only table\n",
    "    table = page_soup.table\n",
    "    \n",
    "    # Get each paragraph tag\n",
    "    paragraphs = table.find_all('p')\n",
    "    \n",
    "    # Use .text to get the inner text for each p\n",
    "    for paragraph in paragraphs:\n",
    "        # print(paragraph.text)\n",
    "        text = paragraph.text\n",
    "        print(text)\n",
    "        \n",
    "        # We are going to split on only the first colon in each row (':') by using text.split(delimeter, 1)\n",
    "        split_text = text.split(':', 1)\n",
    "        \n",
    "        print(split_text)\n",
    "        \n",
    "        # Add this paragraph to the page data\n",
    "        page_data[split_text[0]] = split_text[1]\n",
    "        \n",
    "    # After looping through each paragraph, add this listing to the DataFrame\n",
    "    data.append(page_data)\n",
    "\n",
    "scrape_single_page(links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gzip\n",
    "\n",
    "# This is a simple progress bar library. Nice for long tasks\n",
    "! pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_warn_page(url):\n",
    "    \n",
    "    ## Print the current URL that we're scraping\n",
    "    # print('scraping', url, end='\\r')\n",
    "    \n",
    "    # Fetch the page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # This is pretty atypical. Some of these pages are not being unzipped correctly\n",
    "    # If the request didn't automatically unzip the html, we have to do it ourselves\n",
    "    # We can check the encoding that the requests library thinks the page has returned\n",
    "    if response.apparent_encoding is None:\n",
    "        html = gzip.decompress(response.content).decode('utf-8')\n",
    "    else:\n",
    "        html = response.text\n",
    "        \n",
    "    # Remove non-breaking space characters in the HTML\n",
    "    html = html.replace('&nbsp;', ' ')\n",
    "    \n",
    "    return html\n",
    "    \n",
    "\n",
    "warn_pages = []\n",
    "\n",
    "for link in tqdm(links):\n",
    "    html = get_warn_page(link)\n",
    "    warn_pages.append(html)\n",
    "    \n",
    "    # This is the most important line in the entire notebook\n",
    "    # This line ensures that you won't crash a server. \n",
    "    # It's necessary whenever you are scraping in a loop\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "print('done fetching data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    }
   ],
   "source": [
    "print(len(warn_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done parsing html\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_single_page(html, url):\n",
    "    # Create a dictionary to store the data for a single WARN listing\n",
    "    page_data = {'URL': url}\n",
    "    \n",
    "    # Make the soup for the single page\n",
    "    page_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Sanity check\n",
    "    # print(page_soup.prettify())\n",
    "    \n",
    "    # Get the first table (there should only be one)\n",
    "    table = page_soup.table\n",
    "    \n",
    "    # Get all text in the table\n",
    "    # get_text() will get all text in all elements underneath the current element, \n",
    "    # in this case all of the text in the <p> tags\n",
    "    table_text = table.get_text()\n",
    "    \n",
    "    # Use a regular expression to throw away some extra info we don't care about\n",
    "    table_text = re.split('(?:Additional|Other|Location).*', table_text)[0]\n",
    "    \n",
    "    # Split the text into a list of lines with the newline character '\\n'\n",
    "    lines = table_text.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = line.replace('  ', ' ')\n",
    "        line = line.replace('Dates', 'Date')\n",
    "        line = line.replace('Counties', 'County')\n",
    "        split_text = line.split(':', 1)\n",
    "        # print('split', split_text)\n",
    "        \n",
    "        if len(split_text) == 2:\n",
    "            \n",
    "            key = split_text[0]\n",
    "            value = split_text[1]\n",
    "            \n",
    "            # https://docs.python.org/3/library/re.html\n",
    "#             if re.match('(?:Additional|Other|Location).*', key):\n",
    "#                 page_data['Other sites'] = value\n",
    "#             elif re.match('[0-9]{4}-[0-9]{4}', key):\n",
    "#                 page_data['Other sites'] = value\n",
    "#             else:\n",
    "                \n",
    "            page_data[key] = value\n",
    "    \n",
    "    return page_data\n",
    "\n",
    "\n",
    "# Create a list to store the data we scrape.\n",
    "# Each item in the list will correspond to a single WARN listing\n",
    "# Each column will be a piece of single labeled piece information from the listing\n",
    "data = []\n",
    "\n",
    "for html_page, link in zip(warn_pages, links):\n",
    "    page_data = parse_single_page(html_page, link)\n",
    "    data.append(page_data)\n",
    "    \n",
    "print('done parsing html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "df = pd.DataFrame(data)\n",
    "# df[df['2019-0247']]\n",
    "\n",
    "# df[df['New York City'].notna()]\n",
    "# for row in df:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date of Notice</th>\n",
       "      <th>Event Number</th>\n",
       "      <th>Rapid Response Specialist</th>\n",
       "      <th>Reason Stated for Filing</th>\n",
       "      <th>Company</th>\n",
       "      <th>County</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Business Type</th>\n",
       "      <th>Number Affected</th>\n",
       "      <th>Total Employees</th>\n",
       "      <th>Layoff Date</th>\n",
       "      <th>Closing Date</th>\n",
       "      <th>Reason for Dislocation</th>\n",
       "      <th>FEIN NUM</th>\n",
       "      <th>Union</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7417</td>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>2019-0671</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "      <td>DL1961 Premium Denim Inc. 121 Varick Str...</td>\n",
       "      <td>New York | WDB Name: NEW YORK CITY | Region: ...</td>\n",
       "      <td>Rati Bhandari</td>\n",
       "      <td>(646) 514-9738</td>\n",
       "      <td>Denim Retailer</td>\n",
       "      <td>37</td>\n",
       "      <td>-----</td>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>-----</td>\n",
       "      <td>Unforeseeable business circumstances prompted...</td>\n",
       "      <td>-----</td>\n",
       "      <td>The employees are not represented by a union</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7418</td>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>2019-0670</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Plant Closing</td>\n",
       "      <td>Citizen Watch Company of America, Inc. 5...</td>\n",
       "      <td>Queens | WDB Name: NEW YORK CITY | Region: Ne...</td>\n",
       "      <td>Seth Presser, Vice President, Legal</td>\n",
       "      <td>(212) 497-9795</td>\n",
       "      <td>Watch Manufacturing</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>6/21/2020</td>\n",
       "      <td>6/21/2020</td>\n",
       "      <td>Unforeseeable business circumstances prompted...</td>\n",
       "      <td>-----</td>\n",
       "      <td>Independent Production Maintenance and Servic...</td>\n",
       "      <td>Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7419</td>\n",
       "      <td>3/25/2020</td>\n",
       "      <td>2019-0668</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "      <td>Indochino Apparel (US) Inc. 424 Broome S...</td>\n",
       "      <td>New York/Kings | WDB Name: NEW YORK CITY | Re...</td>\n",
       "      <td>Ryan Mann, Manager, People and Culture - Oper...</td>\n",
       "      <td>(778) 945-2172 Ext: 808</td>\n",
       "      <td>Retail</td>\n",
       "      <td>56</td>\n",
       "      <td>-----</td>\n",
       "      <td>3/25/2020</td>\n",
       "      <td>-----</td>\n",
       "      <td>Unforeseeable business circumstances prompted...</td>\n",
       "      <td>-----</td>\n",
       "      <td>The employees are not represented by a union</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7420</td>\n",
       "      <td>3/16/2020</td>\n",
       "      <td>2019-0699</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Temporary Plant Closing</td>\n",
       "      <td>Howard Beach Fitness Center dba Limitles...</td>\n",
       "      <td>Queens | WDB Name: NEW YORK CITY | Region: Ne...</td>\n",
       "      <td>Joseph Ponte, Operations Manager</td>\n",
       "      <td>(718) 845-4653</td>\n",
       "      <td>Gym</td>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>3/16/2020</td>\n",
       "      <td>3/16/2020</td>\n",
       "      <td>Unforeseeable business circumstances prompted...</td>\n",
       "      <td>-----</td>\n",
       "      <td>The employees are not represented by a union</td>\n",
       "      <td>Temporary Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7421</td>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>2019-0697</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "      <td>Fitzpatrick Grand Central Hotel 141 East...</td>\n",
       "      <td>New York | WDB Name: NEW YORK CITY | Region: ...</td>\n",
       "      <td>Tony Ruscitto, Director of Human Resources</td>\n",
       "      <td>(212) 784-2566</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>57</td>\n",
       "      <td>-----</td>\n",
       "      <td>3/20/2020</td>\n",
       "      <td>-----</td>\n",
       "      <td>Unforeseeable business circumstances prompted...</td>\n",
       "      <td>-----</td>\n",
       "      <td>New York Hotel &amp; Motel Trades Council, AFL-CIO</td>\n",
       "      <td>Temporary Plant Layoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7053</td>\n",
       "      <td>1/6/2020</td>\n",
       "      <td>2019-0207</td>\n",
       "      <td>Frederick Danks</td>\n",
       "      <td>Plant Closing</td>\n",
       "      <td>Macy's Broadway Mall Store (Macy's Retail Hold...</td>\n",
       "      <td>Nassau | WDB Name: OYSTER BAY | Region: Long ...</td>\n",
       "      <td>Heath R. Salit, Human Resources Business Partner</td>\n",
       "      <td>(646) 429-7462</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>Macy's Broadway Mall Store employee separatio...</td>\n",
       "      <td>April 19, 2020; June 29, 2020</td>\n",
       "      <td>Economic</td>\n",
       "      <td>43-0398035</td>\n",
       "      <td>The employees are not represented by a union.</td>\n",
       "      <td>Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7052</td>\n",
       "      <td>12/27/2019</td>\n",
       "      <td>2019-0206</td>\n",
       "      <td>Regenna Darrah</td>\n",
       "      <td>Temporary Plant Closing</td>\n",
       "      <td>Wesley Gardens Nursing Home 3 Upton Park Roche...</td>\n",
       "      <td>Monroe | WDB Name: MONROE | Region: Finger Lakes</td>\n",
       "      <td>Sharon Davis, Human Resources Manager</td>\n",
       "      <td>(585) 241-2105</td>\n",
       "      <td>Nursing Home</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>Beginning on 12/31/2019, with all affected em...</td>\n",
       "      <td>12/27/2019</td>\n",
       "      <td>Due to a water line break</td>\n",
       "      <td>22-3139841</td>\n",
       "      <td>1199 SEIU</td>\n",
       "      <td>Temporary Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7051</td>\n",
       "      <td>12/30/2019</td>\n",
       "      <td>2019-0205</td>\n",
       "      <td>Stuart Goldberg</td>\n",
       "      <td>Plant Closing</td>\n",
       "      <td>127 W. 43rd St. Chophouse, Inc. (Heartla...</td>\n",
       "      <td>New York | WDB Name: NEW YORK CITY | Region: ...</td>\n",
       "      <td>Jon Bloostein, Chief Executive Officer</td>\n",
       "      <td>(917) 999-6532</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>The layoffs are expected to commence on March...</td>\n",
       "      <td>3/31/2020</td>\n",
       "      <td>Economic</td>\n",
       "      <td>13-4141784</td>\n",
       "      <td>The employees are not represented by a union.</td>\n",
       "      <td>Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7050</td>\n",
       "      <td>12/30/2019</td>\n",
       "      <td>2019-0201</td>\n",
       "      <td>Jacqueline Huertas, Karl Price, Regenna Darra...</td>\n",
       "      <td>Plant Closing</td>\n",
       "      <td>New York Express and Logistics, LLC 292 Wolf R...</td>\n",
       "      <td>Albany | WDB Name: CAPITAL DISTRICT | Region:...</td>\n",
       "      <td>Chris Kalavantis, Operations Manager</td>\n",
       "      <td>(617) 968-5311</td>\n",
       "      <td>Trucking company providing freight transporta...</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>3/31/2020</td>\n",
       "      <td>3/31/2020</td>\n",
       "      <td>Contract between New York Express and Logisti...</td>\n",
       "      <td>47-2136557</td>\n",
       "      <td>The employees are not represented by a union.</td>\n",
       "      <td>Plant Closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>https://labor.ny.gov/app/warn/details.asp?id=7049</td>\n",
       "      <td>12/23/2019</td>\n",
       "      <td>2019-0200</td>\n",
       "      <td>Elias Flores</td>\n",
       "      <td>Plant Closing</td>\n",
       "      <td>Benchmark Hospitality of Westchester, LLC (Dor...</td>\n",
       "      <td>Westchester | WDB Name: WESTCH/PTNM | Region:...</td>\n",
       "      <td>Heidi Goodhart, Director of Human Resources</td>\n",
       "      <td>(914) 935-6652</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>1/12/2020</td>\n",
       "      <td>1/12/2020</td>\n",
       "      <td>Loss of funding</td>\n",
       "      <td>47-4737551</td>\n",
       "      <td>The employees are not represented by a union.</td>\n",
       "      <td>Plant Closing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL Date of Notice  \\\n",
       "0    https://labor.ny.gov/app/warn/details.asp?id=7417      3/23/2020   \n",
       "1    https://labor.ny.gov/app/warn/details.asp?id=7418      3/23/2020   \n",
       "2    https://labor.ny.gov/app/warn/details.asp?id=7419      3/25/2020   \n",
       "3    https://labor.ny.gov/app/warn/details.asp?id=7420      3/16/2020   \n",
       "4    https://labor.ny.gov/app/warn/details.asp?id=7421      3/23/2020   \n",
       "..                                                 ...            ...   \n",
       "411  https://labor.ny.gov/app/warn/details.asp?id=7053       1/6/2020   \n",
       "412  https://labor.ny.gov/app/warn/details.asp?id=7052     12/27/2019   \n",
       "413  https://labor.ny.gov/app/warn/details.asp?id=7051     12/30/2019   \n",
       "414  https://labor.ny.gov/app/warn/details.asp?id=7050     12/30/2019   \n",
       "415  https://labor.ny.gov/app/warn/details.asp?id=7049     12/23/2019   \n",
       "\n",
       "    Event Number                          Rapid Response Specialist  \\\n",
       "0      2019-0671                                    Stuart Goldberg   \n",
       "1      2019-0670                                    Stuart Goldberg   \n",
       "2      2019-0668                                    Stuart Goldberg   \n",
       "3      2019-0699                                    Stuart Goldberg   \n",
       "4      2019-0697                                    Stuart Goldberg   \n",
       "..           ...                                                ...   \n",
       "411    2019-0207                                    Frederick Danks   \n",
       "412    2019-0206                                     Regenna Darrah   \n",
       "413    2019-0205                                    Stuart Goldberg   \n",
       "414    2019-0201   Jacqueline Huertas, Karl Price, Regenna Darra...   \n",
       "415    2019-0200                                       Elias Flores   \n",
       "\n",
       "     Reason Stated for Filing  \\\n",
       "0      Temporary Plant Layoff   \n",
       "1               Plant Closing   \n",
       "2      Temporary Plant Layoff   \n",
       "3     Temporary Plant Closing   \n",
       "4      Temporary Plant Layoff   \n",
       "..                        ...   \n",
       "411             Plant Closing   \n",
       "412   Temporary Plant Closing   \n",
       "413             Plant Closing   \n",
       "414             Plant Closing   \n",
       "415             Plant Closing   \n",
       "\n",
       "                                               Company  \\\n",
       "0          DL1961 Premium Denim Inc. 121 Varick Str...   \n",
       "1          Citizen Watch Company of America, Inc. 5...   \n",
       "2          Indochino Apparel (US) Inc. 424 Broome S...   \n",
       "3          Howard Beach Fitness Center dba Limitles...   \n",
       "4          Fitzpatrick Grand Central Hotel 141 East...   \n",
       "..                                                 ...   \n",
       "411  Macy's Broadway Mall Store (Macy's Retail Hold...   \n",
       "412  Wesley Gardens Nursing Home 3 Upton Park Roche...   \n",
       "413        127 W. 43rd St. Chophouse, Inc. (Heartla...   \n",
       "414  New York Express and Logistics, LLC 292 Wolf R...   \n",
       "415  Benchmark Hospitality of Westchester, LLC (Dor...   \n",
       "\n",
       "                                                County  \\\n",
       "0     New York | WDB Name: NEW YORK CITY | Region: ...   \n",
       "1     Queens | WDB Name: NEW YORK CITY | Region: Ne...   \n",
       "2     New York/Kings | WDB Name: NEW YORK CITY | Re...   \n",
       "3     Queens | WDB Name: NEW YORK CITY | Region: Ne...   \n",
       "4     New York | WDB Name: NEW YORK CITY | Region: ...   \n",
       "..                                                 ...   \n",
       "411   Nassau | WDB Name: OYSTER BAY | Region: Long ...   \n",
       "412   Monroe | WDB Name: MONROE | Region: Finger Lakes   \n",
       "413   New York | WDB Name: NEW YORK CITY | Region: ...   \n",
       "414   Albany | WDB Name: CAPITAL DISTRICT | Region:...   \n",
       "415   Westchester | WDB Name: WESTCH/PTNM | Region:...   \n",
       "\n",
       "                                               Contact  \\\n",
       "0                                        Rati Bhandari   \n",
       "1                  Seth Presser, Vice President, Legal   \n",
       "2     Ryan Mann, Manager, People and Culture - Oper...   \n",
       "3                     Joseph Ponte, Operations Manager   \n",
       "4           Tony Ruscitto, Director of Human Resources   \n",
       "..                                                 ...   \n",
       "411   Heath R. Salit, Human Resources Business Partner   \n",
       "412              Sharon Davis, Human Resources Manager   \n",
       "413             Jon Bloostein, Chief Executive Officer   \n",
       "414               Chris Kalavantis, Operations Manager   \n",
       "415        Heidi Goodhart, Director of Human Resources   \n",
       "\n",
       "                        Phone  \\\n",
       "0              (646) 514-9738   \n",
       "1              (212) 497-9795   \n",
       "2     (778) 945-2172 Ext: 808   \n",
       "3              (718) 845-4653   \n",
       "4              (212) 784-2566   \n",
       "..                        ...   \n",
       "411            (646) 429-7462   \n",
       "412            (585) 241-2105   \n",
       "413            (917) 999-6532   \n",
       "414            (617) 968-5311   \n",
       "415            (914) 935-6652   \n",
       "\n",
       "                                         Business Type Number Affected  \\\n",
       "0                                       Denim Retailer              37   \n",
       "1                                  Watch Manufacturing              42   \n",
       "2                                               Retail              56   \n",
       "3                                                  Gym           -----   \n",
       "4                                                Hotel              57   \n",
       "..                                                 ...             ...   \n",
       "411                                       Retail Store             155   \n",
       "412                                       Nursing Home             132   \n",
       "413                                         Restaurant             106   \n",
       "414   Trucking company providing freight transporta...              48   \n",
       "415                                       Resort Hotel             275   \n",
       "\n",
       "    Total Employees                                        Layoff Date  \\\n",
       "0             -----                                          3/23/2020   \n",
       "1                42                                          6/21/2020   \n",
       "2             -----                                          3/25/2020   \n",
       "3             -----                                          3/16/2020   \n",
       "4             -----                                          3/20/2020   \n",
       "..              ...                                                ...   \n",
       "411             155   Macy's Broadway Mall Store employee separatio...   \n",
       "412             132   Beginning on 12/31/2019, with all affected em...   \n",
       "413             106   The layoffs are expected to commence on March...   \n",
       "414              48                                          3/31/2020   \n",
       "415             275                                          1/12/2020   \n",
       "\n",
       "                       Closing Date  \\\n",
       "0                             -----   \n",
       "1                         6/21/2020   \n",
       "2                             -----   \n",
       "3                         3/16/2020   \n",
       "4                             -----   \n",
       "..                              ...   \n",
       "411   April 19, 2020; June 29, 2020   \n",
       "412                      12/27/2019   \n",
       "413                       3/31/2020   \n",
       "414                       3/31/2020   \n",
       "415                       1/12/2020   \n",
       "\n",
       "                                Reason for Dislocation     FEIN NUM  \\\n",
       "0     Unforeseeable business circumstances prompted...        -----   \n",
       "1     Unforeseeable business circumstances prompted...        -----   \n",
       "2     Unforeseeable business circumstances prompted...        -----   \n",
       "3     Unforeseeable business circumstances prompted...        -----   \n",
       "4     Unforeseeable business circumstances prompted...        -----   \n",
       "..                                                 ...          ...   \n",
       "411                                           Economic   43-0398035   \n",
       "412                          Due to a water line break   22-3139841   \n",
       "413                                           Economic   13-4141784   \n",
       "414   Contract between New York Express and Logisti...   47-2136557   \n",
       "415                                    Loss of funding   47-4737551   \n",
       "\n",
       "                                                 Union  \\\n",
       "0         The employees are not represented by a union   \n",
       "1     Independent Production Maintenance and Servic...   \n",
       "2         The employees are not represented by a union   \n",
       "3         The employees are not represented by a union   \n",
       "4       New York Hotel & Motel Trades Council, AFL-CIO   \n",
       "..                                                 ...   \n",
       "411      The employees are not represented by a union.   \n",
       "412                                          1199 SEIU   \n",
       "413      The employees are not represented by a union.   \n",
       "414      The employees are not represented by a union.   \n",
       "415      The employees are not represented by a union.   \n",
       "\n",
       "               Classification  \n",
       "0      Temporary Plant Layoff  \n",
       "1               Plant Closing  \n",
       "2      Temporary Plant Layoff  \n",
       "3     Temporary Plant Closing  \n",
       "4      Temporary Plant Layoff  \n",
       "..                        ...  \n",
       "411             Plant Closing  \n",
       "412   Temporary Plant Closing  \n",
       "413             Plant Closing  \n",
       "414             Plant Closing  \n",
       "415             Plant Closing  \n",
       "\n",
       "[416 rows x 18 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/alex/anaconda3/envs/scraping/lib/python3.8/site-packages (3.0.3)\r\n",
      "Requirement already satisfied: jdcal in /Users/alex/anaconda3/envs/scraping/lib/python3.8/site-packages (from openpyxl) (1.4.1)\r\n",
      "Requirement already satisfied: et-xmlfile in /Users/alex/anaconda3/envs/scraping/lib/python3.8/site-packages (from openpyxl) (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "df.to_excel(\"output.xlsx\")  \n",
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! open ouptut.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
